{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, json\n",
    "from itertools import groupby\n",
    "from datetime import datetime\n",
    "sys.path.append(r\"../\")\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from detectron2.data import MetadataCatalog\n",
    "import cameratransform as ct\n",
    "\n",
    "import ct_assist as cta\n",
    "from ct_assist import reference_detection as rd\n",
    "from ct_assist import transform as ctf\n",
    "from ct_assist.utils import accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"../../dataset2\"\n",
    "anno_dir = data_dir + \"/annotations\"\n",
    "# Local path to images!\n",
    "im_dir = Path(r\"D:\\University\\2020-2021\\Internship\\dataset2\\images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['resolution_max', 'particle_number', 'particle_radius', 'particle_max', 'particle_min', 'particle_band_width', 'time_scale', 'use_adaptive_timesteps', 'flip_ratio', 'viscosity_base', 'viscosity_exponent', 'mesh_scale', 'mesh_particle_radius', 'mesh_concave_lower', 'mesh_concave_upper', 'mesh_smoothen_neg', 'mesh_smoothen_pos', 'cache_directory', 'cache_type', 'cache_frame_end', 'execution_time_data', 'successful_simulation_data', 'execution_time_mesh', 'successful_simulation_mesh', 'fluid_volume_cm3_per_frame', 'area_cm2_per_frame', 'domain_longest_side', 'domain_volume', 'id'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Local path to simulations!\n",
    "with open(r\"D:\\University\\2020-2021\\Internship\\dataset2\\annotations\\simulation_properties.json\") as f:\n",
    "    sims = json.load(f)\n",
    "sim = sims[0]  # Only one simulation filed\n",
    "sim.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local path to images!\n",
    "with open(r\"D:\\University\\2020-2021\\Internship\\dataset2\\annotations\\images.json\") as f:\n",
    "    imgs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/2289 [00:00<?, ?it/s]C:\\Users\\Caspe\\Anaconda3\\envs\\ct_assist\\lib\\site-packages\\detectron2\\modeling\\roi_heads\\fast_rcnn.py:124: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:766.)\n",
      "  filter_inds = filter_mask.nonzero()\n",
      "  3%|██                                                                              | 58/2289 [00:04<39:57,  1.07s/it]d:\\university\\2020-2021\\internship\\ct_assist\\ct_assist\\reference_detection.py:177: SkipFieldWarning: Key `handbag` not found in `height_dict`. Skipped this field.\n",
      "  f\"Key `{key}` not found in `height_dict`. Skipped this field.\", SkipFieldWarning)\n",
      "  3%|██▌                                                                             | 73/2289 [00:05<21:13,  1.74it/s]d:\\university\\2020-2021\\internship\\ct_assist\\ct_assist\\reference_detection.py:177: SkipFieldWarning: Key `bottle` not found in `height_dict`. Skipped this field.\n",
      "  f\"Key `{key}` not found in `height_dict`. Skipped this field.\", SkipFieldWarning)\n",
      "  4%|███▏                                                                            | 91/2289 [00:06<10:55,  3.35it/s]d:\\university\\2020-2021\\internship\\ct_assist\\ct_assist\\reference_detection.py:177: SkipFieldWarning: Key `chair` not found in `height_dict`. Skipped this field.\n",
      "  f\"Key `{key}` not found in `height_dict`. Skipped this field.\", SkipFieldWarning)\n",
      "  5%|███▋                                                                           | 107/2289 [00:07<06:23,  5.69it/s]d:\\university\\2020-2021\\internship\\ct_assist\\ct_assist\\reference_detection.py:177: SkipFieldWarning: Key `suitcase` not found in `height_dict`. Skipped this field.\n",
      "  f\"Key `{key}` not found in `height_dict`. Skipped this field.\", SkipFieldWarning)\n",
      "  8%|██████▏                                                                        | 180/2289 [00:11<02:08, 16.38it/s]d:\\university\\2020-2021\\internship\\ct_assist\\ct_assist\\reference_detection.py:177: SkipFieldWarning: Key `airplane` not found in `height_dict`. Skipped this field.\n",
      "  f\"Key `{key}` not found in `height_dict`. Skipped this field.\", SkipFieldWarning)\n",
      " 22%|█████████████████▏                                                             | 498/2289 [00:36<02:16, 13.16it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e9fdee90b69a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_area\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_cprops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_area\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_area\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_cprops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_area\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-e9fdee90b69a>\u001b[0m in \u001b[0;36mload\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# Extract head-feet pairs from image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0minst_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstances_to_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malways_warn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ct_assist\\lib\\site-packages\\detectron2\\engine\\defaults.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, original_image)\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[0moriginal_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal_image\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maug\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ct_assist\\lib\\site-packages\\detectron2\\data\\transforms\\transform.py\u001b[0m in \u001b[0;36mapply_image\u001b[1;34m(self, img, interp)\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mpil_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"L\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                 \u001b[0mpil_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m             \u001b[0mpil_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterp_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpil_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ct_assist\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   2768\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2770\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2771\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def load():\n",
    "    with open(anno_dir + \"/images.json\") as f:\n",
    "        img_lst = json.load(f)\n",
    "\n",
    "    with open(anno_dir + \"/instance_segmentation.json\") as f:\n",
    "        anno_lst = sorted(json.load(f), key=lambda x: x[\"image_id\"])\n",
    "\n",
    "    predictor, cfg = rd.load_model(return_cfg=True, threshold=0.7)\n",
    "\n",
    "    X = []  # For camera properties test\n",
    "    Y_test = []  # For camera properties test\n",
    "    X_area = []  # For area test\n",
    "    X_cprops = []  # For testing area with known c-props\n",
    "    Y_area = []  # For area test(s)\n",
    "\n",
    "    # dictionary int : str, classes\n",
    "    classes = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).get(\"thing_classes\")\n",
    "    a = 0\n",
    "    # Group annotations by image_id\n",
    "    for k, g in groupby(tqdm(anno_lst), lambda x: x[\"image_id\"]):\n",
    "        a += 1        \n",
    "        # Open image with Pill and cast to np.array\n",
    "        file_name = im_dir / img_lst[k].get(\"file_name\")\n",
    "        img = Image.open(file_name)\n",
    "        arr = np.asarray(img)[...,:3]\n",
    "\n",
    "        # Extract head-feet pairs from image\n",
    "        pred = predictor(arr)\n",
    "        inst_dict = rd.instances_to_dict(pred, classes)\n",
    "        ref = rd.extract_reference(inst_dict, always_warn=False)\n",
    "        # if no references can be found, skip this entry\n",
    "        if len(ref) == 0:\n",
    "            continue\n",
    "        if len(ref[0][0]) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Append kwargs to X\n",
    "        X.append({\"img\": img,\n",
    "                  \"reference\": [],\n",
    "                  \"height\": [],\n",
    "                  \"STD\": [],\n",
    "                  \"meta_data\": {\"focal_length\": 50,\n",
    "                                \"image_size\": (1920, 1080),\n",
    "                                \"sensor_size\": (36, 24)},\n",
    "                  \"multi\": True})\n",
    "        \n",
    "        # Append roll_deg, tilt_deg, heading_deg, elevation_m to Y_test\n",
    "        Y_test.append([img_lst[k].get(key) for key in [\"roll_deg\", \"tilt_deg\", \"heading_deg\", \"elevation\"]])\n",
    "        # Add found reference objects with height and STD to X\n",
    "        for r, h, s in ref:\n",
    "            X[-1][\"reference\"].append(r)\n",
    "            X[-1][\"height\"].append(h)\n",
    "            X[-1][\"STD\"].append(s)\n",
    "\n",
    "        # Only sim_id 0.0 has fluid area saved, so only store those for test\n",
    "        sim_id = img_lst[k].get(\"simulation_id\")\n",
    "        if sim_id == 0.0:\n",
    "            segs = None\n",
    "            # Get only fluid spill polygons\n",
    "            for anno in filter(lambda x: x[\"category_id\"] == 0, g):                \n",
    "                segs = anno[\"segmentation\"]\n",
    "            # If any fluid spill polygons are found  \n",
    "            if segs:\n",
    "                # Simulation frame\n",
    "                frame = img_lst[k].get(\"frame\")\n",
    "                # Copy most recent record from X to X_area\n",
    "                X_area.append(X[-1].copy())\n",
    "                # Add image coords and area in m^2 per frame to respective datasets\n",
    "                X_area[-1][\"image_coords\"] = [np.array(list(zip(a[::2], a[1::2]))) for a in segs]\n",
    "                Y_area.append(sim[\"area_cm2_per_frame\"][frame] / 10_000)\n",
    "                # Add kwargs to X_cprops\n",
    "                X_cprops.append((Y_test[-1], X[-1][\"meta_data\"], X_area[-1][\"image_coords\"], img))\n",
    "    \n",
    "    return X, Y_test, X_area, X_cprops, Y_area\n",
    "\n",
    "X, Y_test, X_area, X_cprops, Y_area = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_n(X=X_c, Y=Y_c, X_area=X_area, Y_area=Y_area, n=3):\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \":: Testing camera properties...\")\n",
    "    \n",
    "    score1 = [accuracy.camera_properties(X, Y) for _ in range(n)]\n",
    "    arrs = []\n",
    "    for i in range(len(Y)):\n",
    "        arr = np.zeros(4)\n",
    "        for m in range(n):\n",
    "            arr += score1[m][1][i]\n",
    "        \n",
    "        arrs.append(arr / n)\n",
    "    arrs = np.asarray(arrs)\n",
    "    Y = np.asarray(Y)\n",
    "    avg_prop_rmse = (mean_squared_error(Y[:, 0], arrs[:, 0], squared=False),\n",
    "            mean_squared_error(Y[:, 1], arrs[:, 1], squared=False),\n",
    "            mean_squared_error(Y[:, 2], arrs[:, 2], squared=False),\n",
    "            mean_squared_error(Y[:, 3], arrs[:, 3], squared=False))\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \":: Finished testing camera properties.\")\n",
    "    \n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \":: Testing Fluid area...\")\n",
    "    \n",
    "    score2 = [accuracy.area(X_area, Y_area) for _ in range(n)]\n",
    "    areas = []\n",
    "    for j in range(len(score2[0][1])):\n",
    "        area = 0\n",
    "        for m in range(n):\n",
    "            area += score2[m][1][j]\n",
    "        areas.append(area / n)\n",
    "            \n",
    "    areas = np.asarray(areas)\n",
    "    avg_area_rmse = mean_squared_error(Y_area, areas, squared=False)\n",
    "    \n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(current_time, \":: Finished testing fluid area.\")\n",
    "    \n",
    "    print(\"Camera properties:\", *[s[0] for s in score1], sep=\"\\n\")\n",
    "    print(\"Camera properties averaged:\", avg_prop_rmse)\n",
    "    print()\n",
    "    print(\"Spill area:\", *[s[0] for s in score2], sep=\"\\n\")\n",
    "    print(\"Spill area averaged:\", avg_area_rmse)\n",
    "\n",
    "run_n(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy X and Y_test for testing\n",
    "X_c = X.copy()\n",
    "Y_c = Y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "_points = []\n",
    "\n",
    "# Test area with known camera properties\n",
    "def make_cam(roll_deg, tilt_deg, heading_deg, elevation, focal_length, image_size, sensor_size, img_cords, img):\n",
    "\n",
    "    proj = ct.RectilinearProjection(focallength_mm=focal_length,\n",
    "                                         sensor=sensor_size,\n",
    "                                         image=image_size)\n",
    "    # initialize the camera\n",
    "    cam = ct.Camera(projection=proj, orientation=ct.SpatialOrientation(elevation_m=elevation,\n",
    "                                          tilt_deg=tilt_deg,\n",
    "                                          heading_deg=heading_deg,\n",
    "                                          roll_deg=roll_deg\n",
    "                                          ))\n",
    "    \n",
    "    \n",
    "    points = (cam.spaceFromImage(points=x) for x in img_cords)\n",
    "    global imgs\n",
    "    imgs.append(img)\n",
    "    global _points\n",
    "    _points.append(points)\n",
    "    areas = sum(accuracy.calc_area(poly[:, :2]) for poly in points)\n",
    "    return areas\n",
    "areas = [make_cam(*ext, **inte, img_cords=imp, img=img) for ext, inte, imp, img in tqdm(X_cprops)]\n",
    "print(areas)\n",
    "mean_squared_error(Y_area, areas, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score, ypred, ytue = accuracy.camera_properties(X_c, Y_c)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score2, pred_area = accuracy.area(X_area, Y_area)\n",
    "score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, figsize=(15, 15))\n",
    "\n",
    "# for i in [0, 1, 3]:\n",
    "# ax[0].plot(ypred[...,0], label=\"pred\")\n",
    "# ax[0].plot(ytue[..., 0], label=\"true\")\n",
    "\n",
    "ax[0].scatter(range(ytue.shape[0]), ytue[..., 0], label=\"True\")\n",
    "ax[0].scatter(range(ytue.shape[0]), ypred[...,0], label=\"Predicted\")\n",
    "ax[0].set_title(\"Roll degree\")\n",
    "\n",
    "\n",
    "# ax[1].plot(ypred[...,1], label=\"pred\")\n",
    "# ax[1].plot(ytue[..., 1], label=\"true\")\n",
    "ax[1].scatter(range(ytue.shape[0]), ytue[..., 1], label=\"True\")\n",
    "ax[1].scatter(range(ytue.shape[0]), ypred[...,1], label=\"Predicted\")\n",
    "ax[1].set_title(\"Tilt degree\")\n",
    "\n",
    "# ax[2].plot(ypred[...,3], label=\"pred\")\n",
    "# ax[2].plot(ytue[..., 3], label=\"true\")\n",
    "ax[2].scatter(range(ytue.shape[0]), ytue[..., 3], label=\"True\")\n",
    "ax[2].scatter(range(ytue.shape[0]), ypred[...,3], label=\"Predicted\")\n",
    "ax[2].set_title(\"Elevation (m)\")\n",
    "\n",
    "ax[3].set_yscale('log')\n",
    "ax[3].scatter(range(len(X_area)), Y_area, label=\"True\")\n",
    "ax[3].scatter(range(len(X_area)), pred_area, label=\"Predicted\")\n",
    "# ax[3].scatter(range(len(X_area)), areas, label=\"Predicted with known camera properties\")\n",
    "ax[3].set_title(\"Area (m$^{2}$) (log-scaled)\")\n",
    "\n",
    "\n",
    "# ax[3].set_yscale('log')\n",
    "ax[4].scatter(range(len(X_area)), Y_area, label=\"True\")\n",
    "ax[4].scatter(range(len(X_area)), pred_area, label=\"Predicted\")\n",
    "# ax[4].scatter(range(len(X_area)), areas, label=\"Predicted with known camera properties\")\n",
    "ax[4].set_title(\"Area (m$^{2}$)\")\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
