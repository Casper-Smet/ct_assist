{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "model = model_zoo.get(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\", trained=True)\n",
    "\n",
    "# sys.path.append(r\"../\")\n",
    "from ct_assist import transform\n",
    "from ct_assist.utils import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance\n",
    "In this Notebook, I will be performance testing various parts of the ct_assist library. This includes both speed and accuracy testing.\n",
    "\n",
    "First getting the testing data ready:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_coord_dict = dict()\n",
    "image_coord_dict[\"00.jpg\"] = np.array([[1470, 1430], [2333, 1355], [3247, 1781], [1935, 1952]])\n",
    "image_coord_dict[\"01.jpg\"] = np.array([[1495, 1552], [2219, 1589], [1843, 1969], [805, 1875]])\n",
    "image_coord_dict[\"03.jpg\"] = np.array([[1216, 1398], [2215, 1754], [3268, 1530], [2067, 1282]])   \n",
    "\n",
    "def setup_vars():\n",
    "    \"\"\"Loads data for test_transform_image\"\"\"\n",
    "    data_dir = r\"./data/table\"\n",
    "    json_fp = os.path.join(data_dir, \"anno.json\")\n",
    "    arr_fp = os.path.join(data_dir, \"anno.npz\")\n",
    "    with open(json_fp, \"r\") as fp:\n",
    "        mappings = json.load(fp)\n",
    "\n",
    "    with np.load(arr_fp) as arrs:\n",
    "        anno_dict = {img: {\"heads\": arrs[f\"{prefix}heads\"],\n",
    "                           \"feet\": arrs[f\"{prefix}feet\"]}\n",
    "                     for img, prefix in mappings.items()}\n",
    "    \n",
    "    for key, items in anno_dict.items():\n",
    "        if key.endswith(\"02.jpg\"):\n",
    "            continue\n",
    "        else:\n",
    "            image_coords = image_coord_dict[key[-6:]]\n",
    "        # feet and heads have been swapped in annotations\n",
    "        reference = np.array([items[\"feet\"], items[\"heads\"]])\n",
    "        height = 0.095  # m\n",
    "        STD = 0.01  # m\n",
    "        img = Image.open(key)\n",
    "        yield (img, reference, height, STD, image_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generator = setup_vars()\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "coords_sq = (transform.fit_transform(*params)[:, :2] for params in generator)\n",
    "y_pred = np.array([accuracy.calc_area(poly) for poly in coords_sq])\n",
    "pr.disable()\n",
    "pr.print_stats(\"tottime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "As the \"real\" positions in images currently aren't known, in order to figure out how close CameraTransform is to \"real\" positions, we have to take a derivative of these positions. For the purposes of this assignment, I've chosen the area of the polygon, as this is an important variable in the use case.\n",
    "\n",
    "The three images used for testing all feature a table with a area of `133` cm$^{2}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.repeat(1.33455, y_pred.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An RMSE of around 20 square centimeters is adequate. Especially the latter two images are taken and worse angles and are insufficiently labeled in comparison to `img_03.jpg`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
